<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html><head><title></title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>
<div style="page-break-before:always; page-break-after:always"><div><p>96   Kim, Street &amp; Menczer<br/></p>
<p>Copyright &#169; 2003, Idea Group Inc. Copying or distributing in print or electronic forms without written<br/>permission of Idea Group Inc. is prohibited.<br/></p>
<p>For this purpose, we selected Pareto solutions across all different <i>K</i> values that have<br/>fewer than 10 features including lymph node information, and formed three clusters using<br/>these selected features, disregarding the evolved value of <i>K</i>. The survival characteristics<br/>of the three prognostic groups found by the best of these solutions were very competitive<br/>with our chosen solution. The good prognostic group was welldifferentiated from the<br/>intermediate group (p &lt; 0.10), and the difference between the intermediate group and the<br/>poor group was significant (p &lt; 0.026). This suggests that lymph node status may indeed<br/>have strong prognostic effects, even though it is excluded from the best models evolved<br/>by our algorithms.<br/></p>
<p><b>Conclusions<br/></b>In this section, we presented a new ELSA/EM algorithm for unsupervised feature<br/></p>
<p>selection. Our ELSA/EM model outperforms a greedy algorithm in terms of classification<br/>accuracy while considering a number of possibly conflicting heuristic metrics. Most<br/>importantly, our model can reliably select an appropriate clustering model, including<br/>significant features and the number of clusters.<br/></p>
<p>In future work, we would like to compare the performance of ELSA on the unsuper-<br/>vised feature selection task with other multi-objective EAs, using each in conjunction<br/>with clustering algorithms. Another promising future direction will be a direct compari-<br/>son of different clustering algorithms in terms of the composition of selected features and<br/>prediction accuracy.<br/></p>
<p><b>FEATURE SELECTION FOR ENSEMBLES<br/></b>In this section, we propose a new meta-ensembles algorithm to directly optimize<br/></p>
<p>ensembles by creating a two-level evolutionary environment.  In particular, we employ<br/>feature selection not only to increase the prediction accuracy of an individual classifier,<br/>but also to promote diversity among component classifiers in an ensemble (Opitz, 1999).<br/></p>
<p><b>Feature Selection and Ensembles<br/></b>Recently, many researchers have combined the predictions of multiple classifiers<br/></p>
<p>to produce a better classifier, an ensemble, and often have reported improved perfor-<br/>mance (Bauer &amp; Kohavi, 1999;Breiman, 1996b). Bagging (Breiman, 1996a) and Boosting<br/>(Freund &amp; Schapire, 1996) are the most popular methods for creating accurate ensembles.<br/>The effectiveness of Bagging and Boosting comes primarily from the diversity caused<br/>by resampling training examples while using the complete set of features to train<br/>component classifiers.<br/></p>
<p>Recently, several attempts have been made to incorporate the diversity in feature<br/>dimension into ensemble methods. The Random Subspace Method (RSM) in Ho (1998a<br/>&amp; 1998b) was one early algorithm that constructed an ensemble by varying the feature<br/>subset. RSM used C4.5 as a base classifier and randomly chose half of the original<br/>features to build each classifier. In Guerra-Salcedo and Whitley(1999), four different</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Feature Selection in Data Mining   97<br/></p>
<p>Copyright &#169; 2003, Idea Group Inc. Copying or distributing in print or electronic forms without written<br/>permission of Idea Group Inc. is prohibited.<br/></p>
<p>ensemble methods were paired with each of three different feature selection algorithms:<br/>complete, random, and genetic search. Using two table-based classification methods,<br/>ensembles constructed using features selected by the GA showed the best performance.<br/>In Cunningham and Carney (2000), a new entropy measure of the outputs of the<br/>component classifiers was used to explicitly measure the ensemble diversity and to<br/>produce good feature subsets for ensemble using hill-climbing search.<br/></p>
<p>Genetic Ensemble Feature Selection (GEFS) (Opitz, 1999) used a GA to search for<br/>possible feature subsets. GEFS starts with an initial population of classifiers built using up<br/>to 2<i>D</i> features, where <i>D</i> is the complete feature dimension. It is possible for some features to<br/>be selected more than once in GEFS, and crossover and mutation operators are used to search<br/>for new feature subsets. Using 100 most-fit members with majority voting scheme, GEFS<br/>reported better estimated generalization than Bagging and AdaBoost on about two-thirds<br/>of 21 data sets tested.  Longer chromosomes, however, make GEFS computationally<br/>expensive in terms of memory usage (Guerra-Salcedo &amp; Whitley, 1999).  Further, GEFS<br/>evaluates each classifier after combining two objectives in a subjective manner using <i>fitness<br/>= accuracy + </i>&#955;<i> diversity</i>, where <i>diversity</i> is the average difference between the prediction<br/>of component classifiers and the ensemble.<br/></p>
<p>However, all these methods consider only one ensemble. We propose a new<br/>algorithm for ensemble feature selection, Meta-Evolutionary Ensembles (MEE), that<br/>considers multiple ensembles simultaneously and allows each component classifier to<br/>move into the best-fit ensemble. We evaluate and reward each classifier based on two<br/>different criteria, accuracy and diversity. A classifier that correctly predicts data<br/>examples that other classifiers in the same ensemble misclassify contributes more to the<br/>accuracy of the ensemble to which it belongs.  We imagine that some limited &#8220;energy&#8221;<br/>is evenly distributed among the examples in the data set. Each classifier is rewarded with<br/>some portion of the energy if it correctly predicts an example. The more classifiers that<br/>correctly classify a specific example, the less energy is rewarded to each, encouraging<br/>them to correctly predict the more difficult examples. The predictive accuracy of each<br/>ensemble determines the total amount of energy to be replenished at each generation.<br/>Finally, we select the ensemble with the highest accuracy as our final model.<br/></p>
<p><b>Meta-Evolutionary Ensembles<br/></b>Pseudocode for the Meta-Evolutionary Ensembles (MEE) algorithm is shown in<br/></p>
<p>Figure 10, and a graphical depiction of the energy allocation scheme is shown in Figure<br/>11.<br/></p>
<p>Each agent (candidate solution) in the population is first initialized with randomly<br/>selected features, a random ensemble assignment, and an initial reservoir of energy. The<br/>representation of an agent consists of <i>D + log2</i>(<i>G</i>) bits. <i>D</i> bits correspond to the selected<br/>features (1 if a feature is selected, 0 otherwise). The remaining bits are a binary<br/>representation of the ensemble index, where <i>G</i> is the maximum number of ensembles.<br/>Mutation and crossover operators are used to explore the search space and are defined<br/>in the same way as in previous section.<br/></p>
<p>In each iteration of the algorithm, an agent explores a candidate solution (classifier)<br/>similar to itself, obtained via crossover and mutation. The agent&#8217;s bit string is parsed to get<br/>a feature subset <i>J</i>.  An ANN is then trained on the projection of the data set onto <i>J</i>, and returns</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>98   Kim, Street &amp; Menczer<br/></p>
<p>Copyright &#169; 2003, Idea Group Inc. Copying or distributing in print or electronic forms without written<br/>permission of Idea Group Inc. is prohibited.<br/></p>
<p><i>Figure 10: Pseudo-code of Meta-Evolutionary Ensembles (MEE) algorithm.<br/></i></p>
<p><i>Figure 11: Graphical depiction of energy allocation in the MEE. Individual classifiers<br/>(small boxes in the environment) receive energy by correctly classifying test points.<br/>Energy for each ensemble is replenished between generations based on the accuracy<br/>of the ensemble. Ensembles with higher accuracy have their energy bins replenished<br/>with more energy per classifier, as indicated by the varying widths of the bins.<br/></i></p>
<p>initialize population of agents, each with energy &#952;<i>/2<br/></i>while there are alive agents in <i>Popi</i> and <i>i &lt; T<br/></i>      for each ensemble <i>g<br/></i>            for each record <i>r</i> in <i>Datatest<br/></i></p>
<p><i>    prevCountg,r</i> = <i>countg,r</i>;  <i>countg,r</i> = 0;<br/>            for each agent <i>a</i> in <i>Popi<br/></i></p>
<p><i>    a&#8217; = mutate</i>(<i>crossover</i>(<i>a, randomMate</i>));<br/><i>    g  = group</i>(<i>a</i>);<br/>    train(<i>a</i>);<br/>    for each record <i>r</i> in <i>Datatest<br/></i>          if (<i>class</i>(<i>r</i>) == <i>prediction</i>(<i>r,a</i>))<br/></p>
<p><i> countg,r</i>++;   &#8710;<i>E</i> = <i>Eenvt<br/></i>g,r / <i>min</i>(5, <i>prevCountg,r</i>);<br/></p>
<p><i> Eenvt<br/></i>g,r = <i>Eenvt<br/></i></p>
<p>g,r - &#8710;<i>E</i>;  <i>Ea</i> = <i>Ea</i> + &#8710;<i>E</i>;<br/><i>    Ea</i> = <i>Ea - Ecost</i>;<br/>    if (E<i>a</i> &gt; &#952;)<br/>          insert <i>a, a&#8217;</i> into <i>Pop</i>i+1; <i>Ea&#8217; = Ea / 2</i>; <i>Ea = Ea - Ea&#8217;</i> ;<br/>    else if (<i>Ea &gt; 0</i>)<br/>          insert <i>a</i> into <i>Pop</i>i+1;<br/></p>
<p>      for each ensemble <i>g<br/></i>            replenish energy based on predictive accuracy;<br/><i>      i = i+</i>1;<br/>endwhile</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>Feature Selection in Data Mining   99<br/></p>
<p>Copyright &#169; 2003, Idea Group Inc. Copying or distributing in print or electronic forms without written<br/>permission of Idea Group Inc. is prohibited.<br/></p>
<p>the predicted class labels for the test examples. The agent collects &#8710;<i>E</i> from each example it<br/>correctly classifies, and is taxed once with <i>Ecost.</i> The net energy intake of an agent is determined<br/>by its classification accuracy. But the energy also depends on the state of the environment.<br/>We have an energy source for each ensemble, divided into bins corresponding to each data<br/>point. For ensemble <i>g</i> and record index <i>r</i> in the test data, the environment keeps track of energy<br/><i>Eenvt<br/></i></p>
<p><i>g,r</i> and the number of agents in ensemble <i>g</i>, <i>countg,r</i> that correctly predict record <i>r</i>. The<br/>energy received by an agent for each correctly classified record <i>r</i> is given by<br/></p>
<p>&#8710;<i>E</i> = <i>Eenvt<br/>g,r</i> / <i>min</i>(5, <i>prevCountg,r</i>). (10)<br/></p>
<p>An agent receives greater reward for correctly predicting an example that most in its<br/>ensemble get wrong. The <i>min</i> function ensures that for a given point there is enough energy<br/>to reward at least five agents in the new generation. Candidate solutions receive energy only<br/>inasmuch as the environment has sufficient resources; if these are depleted, no benefits are<br/>available until the environmental resources are replenished. Thus, an agent is rewarded with<br/>energy for its high fitness values, but also has an interest in finding unpopulated niches,<br/>where more energy is available. The result is a natural bias toward diverse solutions in the<br/>population. <i>Ecost </i>for any action is a constant (<i>Ecost</i> &lt; &#952;).<br/></p>
<p>In the selection part of the algorithm, an agent compares its current energy level with<br/>a constant reproduction threshold &#952;.  If its energy is higher than &#952;, the agent reproduces; the<br/>agent and its mutated clone become part of the new population, with the offspring receiving<br/>half of its parent&#8217;s energy.  If the energy level of an agent is positive but lower than &#952;, only<br/>that agent joins the new population.<br/></p>
<p>The environment for each ensemble is replenished with energy based on its<br/>predictive accuracy, as determined by majority voting with equal weight among base<br/>classifiers.  We sort the ensembles in ascending order of estimated accuracy and<br/>apportion energy in linear proportion to that accuracy, so that the most accurate<br/>ensemble is replenished with the greatest amount of energy per base classifier. Since the<br/>total amount of energy replenished also depends on the number of agents in each<br/>ensemble, it is possible that an ensemble with lower accuracy can be replenished with<br/>more energy in total than an ensemble with higher accuracy.<br/></p>
<p><b>Experimental Results<br/></b><i>Experimental results of MEE/ANN<br/></i></p>
<p>We tested the performance of MEE combined with neural networks on several data<br/>sets that were used in Opitz(1999).  In our experiments, the weights and biases of the<br/>neural networks are initialized randomly between 0.5 and -0.5, and the number of hidden<br/>nodes is determined heuristically as the square root of <i>inputs</i>. The other parameters for<br/>the neural networks include a learning rate of 0.1 and a momentum rate of 0.9. The number<br/>of training epochs was kept small for computational reasons. The values for the various<br/>parameters are: Pr(<i>mutation</i>) = 1.0,  Pr(<i>crossover</i>) = 0.8, <i>Ecost</i> = 0.2, <i>q</i> = 0.3, and <i>T</i> = 30. The<br/>value of <i>Eenvt<br/></i></p>
<p><i>tot</i> = 30 is chosen to maintain a population size around 100 classifier agents.<br/>Experimental results are shown in Table 4. All computational results for MEE are<br/></p>
<p>based on the performance of the best ensemble and are averaged over five standard 10-</p>

</div></div>
<div style="page-break-before:always; page-break-after:always"><div><p>100   Kim, Street &amp; Menczer<br/></p>
<p>Copyright &#169; 2003, Idea Group Inc. Copying or distributing in print or electronic forms without written<br/>permission of Idea Group Inc. is prohibited.<br/></p>
<p><i>Table 4: Experimental results of MEE/ANN<br/></i></p>
<p>Single net MEE Data sets  Avg.   S.D. Bagging AdaBoost GEFS Avg. S.D. Epochs <br/>Credita  84.3   0.30 86.2 84.3 86.8 86.4 0.52 40 <br/>Creditg  71.7   0.43 75.8 74.7 75.2 75.6 0.78 50 <br/>Diabetes  76.4   0.93 77.2 76.7 77.0 76.8 0.42 50 <br/>Glass  57.1   2.69 66.9 68.9 69.6 61.1 1.73 100 <br/>Cleveland  80.7   1.83 83.0 78.9 83.9 83.3 1.54 50 <br/>Hepatitis  81.5   0.21 82.2 80.3 83.3 84.9 0.65 40 <br/>Votes-84  95.9   0.41 95.9 94.7 95.6 96.1 0.44 40 <br/>Hypo  93.8   0.09 93.8 93.8 94.1 93.9 0.06 50 <br/>Ionosphere  89.3   0.85 90.8 91.7 94.6 93.5 0.81 100 <br/>Iris  95.9   1.10 96.0 96.1 96.7 96.5 0.73 100 <br/>Krvskp  98.8   0.63 99.2 99.7 99.3 99.3 0.10 50 <br/>Labor  91.6   2.29 95.8 96.8 96.5 94.4 0.78 50 <br/>Segment  92.3   0.97 94.6 96.7 96.4 93.2 0.28 50 <br/>Sick  95.2   0.47 94.3 95.5 96.5 99.3 0.03 50 <br/>Sonar  80.5   2.03 83.2 87.0 82.2 85.2 1.57 100 <br/>Soybean  92.0   0.92 93.1 93.7 94.1 93.8 0.19 50 <br/>Vehicle  74.7   0.48 79.3 80.3 81.0 76.4 1.12 50 <br/>Win-loss-tie       15-0-2 7-4-6 9-6-2 4-7-6  <br/></p>
<p> <br/></p>
<p>fold cross-validation experiments. Within the training algorithm, each ANN is trained on<br/>two-thirds of the training set and tested on the remaining third for energy allocation<br/>purposes.  We present the performance of a single neural network using the complete<br/>set of features as a baseline algorithm.  In the win-loss-tie results shown at the bottom<br/>of Table 4, a comparison is considered a tie if the intervals defined by one standard error8<br/></p>
<p>of the mean overlap. Of the data sets tested, MEE shows consistent improvement over<br/>a single neural network.<br/></p>
<p>We also include the results of Bagging, AdaBoost, and GEFS from Opitz (1999) for<br/>indirect comparison.  In these comparisons, we did not have access to the accuracy<br/>results of the individual runs.  Therefore, a tie is conservatively defined as a test in which<br/>the one standard-deviation interval of our test contained the point estimate of accuracy<br/>from Opitz(1999). In terms of predictive accuracy, our algorithm demonstrates better or<br/>equal performance compared to single neural networks, Bagging and Boosting. However,<br/>MEE shows slightly worse performance compared to GEFS, possibly due to the method-<br/>ological differences. For example, it is possible that the more complex structure of neural<br/>networks used in GEFS can learn more difficult patterns in data sets such as Glass and<br/>Labor data.<br/></p>
<p>From the perspective of computational complexity, our algorithm can be very slow<br/>compared to Bagging and Boosting. However, MEE can be very fast compared to GEFS,<br/>because GEFS uses twice as many as input features as MEE. Further, the larger number<br/>of hidden nodes and longer training epochs can make GEFS extremely slow.</p>

</div></div>
</body></html>